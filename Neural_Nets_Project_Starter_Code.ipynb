{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8312969,"sourceType":"datasetVersion","datasetId":4938396}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gesture Recognition\nIn this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started.","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:00:19.484329Z","iopub.execute_input":"2024-05-05T19:00:19.484781Z","iopub.status.idle":"2024-05-05T19:00:19.497780Z","shell.execute_reply.started":"2024-05-05T19:00:19.484720Z","shell.execute_reply":"2024-05-05T19:00:19.496806Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install imageio\n!pip install opencv-python","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:00:19.499812Z","iopub.execute_input":"2024-05-05T19:00:19.500126Z","iopub.status.idle":"2024-05-05T19:00:46.007769Z","shell.execute_reply.started":"2024-05-05T19:00:19.500095Z","shell.execute_reply":"2024-05-05T19:00:46.006817Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (2.33.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from imageio) (1.26.4)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio) (9.5.0)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom cv2 import imread, resize, imshow\nfrom matplotlib import pyplot as plt\nimport datetime\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:00:46.009102Z","iopub.execute_input":"2024-05-05T19:00:46.009443Z","iopub.status.idle":"2024-05-05T19:00:46.428317Z","shell.execute_reply.started":"2024-05-05T19:00:46.009414Z","shell.execute_reply":"2024-05-05T19:00:46.427608Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"We set the random seed so that the results don't vary drastically.","metadata":{}},{"cell_type":"code","source":"np.random.seed(30)\nimport random as rn\nrn.seed(30)\nfrom keras import backend as K\nimport tensorflow as tf\ntf.random.set_seed(30)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:00:46.430160Z","iopub.execute_input":"2024-05-05T19:00:46.431334Z","iopub.status.idle":"2024-05-05T19:01:05.204834Z","shell.execute_reply.started":"2024-05-05T19:00:46.431310Z","shell.execute_reply":"2024-05-05T19:01:05.204003Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-05 19:00:49.797087: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-05 19:00:49.797212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-05 19:00:50.079380: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error.","metadata":{}},{"cell_type":"code","source":"# train_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/train.csv').readlines())\n# val_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/val.csv').readlines())\n\ntrain_doc = np.random.permutation(open('/kaggle/input/gesture-recognition-dataset/Project_data/train.csv').readlines())\nval_doc = np.random.permutation(open('/kaggle/input/gesture-recognition-dataset/Project_data/val.csv').readlines())\n\nbatch_size = 10","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:05.205949Z","iopub.execute_input":"2024-05-05T19:01:05.206447Z","iopub.status.idle":"2024-05-05T19:01:05.234543Z","shell.execute_reply.started":"2024-05-05T19:01:05.206421Z","shell.execute_reply":"2024-05-05T19:01:05.233746Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Generator\nThis is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy.","metadata":{}},{"cell_type":"code","source":"def generator(source_path, folder_list, batch_size):\n    print( 'Source path = ', source_path, '; batch size =', batch_size)\n    img_idx = range(30)\n    x = len(img_idx)\n    y = 60\n    z = 80\n    while True:\n        t = np.random.permutation(folder_list)\n        num_batches = len(folder_list) // batch_size\n        \n        for batch in range(num_batches): # we iterate over the number of batches\n            \n            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n            for folder in range(batch_size): # iterate over the batch_size\n                t_list_index = folder + (batch*batch_size)\n                imgs = os.listdir(source_path+'/'+ t[t_list_index].split(';')[0]) # read all the images in the folder\n                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n                    image = imread(source_path+'/'+ t[t_list_index].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n                    \n                    #crop the images and resize them. Note that the images are of 2 different shape \n                    #and the conv3D will throw error if the inputs in a batch have different shapes\n                    \n                    # Reshaping it to y*z (or 60*80) pixels\n                    image = resize(image, dsize=(z,y))\n                    \n                    batch_data[folder,idx,:,:,0] = (image[:,:,0] - np.percentile(image[:,:,0],5)) / (np.percentile(image[:,:,0],95) - np.percentile(image[:,:,0],5)) #normalise and feed in the image\n                    batch_data[folder,idx,:,:,1] = (image[:,:,1] - np.percentile(image[:,:,1],5)) / (np.percentile(image[:,:,1],95) - np.percentile(image[:,:,1],5)) #normalise and feed in the image\n                    batch_data[folder,idx,:,:,2] = (image[:,:,2] - np.percentile(image[:,:,2],5)) / (np.percentile(image[:,:,2],95) - np.percentile(image[:,:,2],5)) #normalise and feed in the image\n                    \n                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n\n        \n        # write the code for the remaining data points which are left after full batches\n        \n        next_t_index = (t_list_index+1)\n        last_batch_size = len(t) - (t_list_index+1)\n        batch_data = np.zeros((last_batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n        batch_labels = np.zeros((last_batch_size,5)) # batch_labels is the one hot representation of the output\n        for folder, t_list_index in enumerate( range(next_t_index, len(t)) ): # iterate over the batch_size\n            imgs = os.listdir(source_path+'/'+ t[t_list_index].split(';')[0]) # read all the images in the folder\n            for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n                image = imread(source_path+'/'+ t[t_list_index].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n                image = resize(image, dsize=(z,y))\n                \n                batch_data[folder,idx,:,:,0] = (image[:,:,0] - np.percentile(image[:,:,0],5)) / (np.percentile(image[:,:,0],95) - np.percentile(image[:,:,0],5)) #normalise and feed in the image\n                batch_data[folder,idx,:,:,1] = (image[:,:,1] - np.percentile(image[:,:,1],5)) / (np.percentile(image[:,:,1],95) - np.percentile(image[:,:,1],5)) #normalise and feed in the image\n                batch_data[folder,idx,:,:,2] = (image[:,:,2] - np.percentile(image[:,:,2],5)) / (np.percentile(image[:,:,2],95) - np.percentile(image[:,:,2],5)) #normalise and feed in the image\n\n            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n        yield batch_data, batch_labels\n            \n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:05.235832Z","iopub.execute_input":"2024-05-05T19:01:05.236152Z","iopub.status.idle":"2024-05-05T19:01:05.257533Z","shell.execute_reply.started":"2024-05-05T19:01:05.236118Z","shell.execute_reply":"2024-05-05T19:01:05.256858Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture.","metadata":{}},{"cell_type":"code","source":"# train_path = '/notebooks/storage/Final_data/Collated_training/train'\n# val_path = '/notebooks/storage/Final_data/Collated_training/val'\n\ntrain_path = '/kaggle/input/gesture-recognition-dataset/Project_data/train'\nval_path = '/kaggle/input/gesture-recognition-dataset/Project_data/val'\n\ncurr_dt_time = datetime.datetime.now()\nnum_train_sequences = len(train_doc)\nprint('# training sequences =', num_train_sequences)\nnum_val_sequences = len(val_doc)\nprint('# validation sequences =', num_val_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:05.258669Z","iopub.execute_input":"2024-05-05T19:01:05.258953Z","iopub.status.idle":"2024-05-05T19:01:05.273498Z","shell.execute_reply.started":"2024-05-05T19:01:05.258930Z","shell.execute_reply":"2024-05-05T19:01:05.272726Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"# training sequences = 663\n# validation sequences = 100\n","output_type":"stream"}]},{"cell_type":"code","source":"generator_test = generator(train_path, train_doc, batch_size)\nbatch_data, batch_labels = generator_test.__next__()\nbatch_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:05.274973Z","iopub.execute_input":"2024-05-05T19:01:05.275284Z","iopub.status.idle":"2024-05-05T19:01:08.969480Z","shell.execute_reply.started":"2024-05-05T19:01:05.275256Z","shell.execute_reply":"2024-05-05T19:01:08.968514Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Source path =  /kaggle/input/gesture-recognition-dataset/Project_data/train ; batch size = 10\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(10, 30, 60, 80, 3)"},"metadata":{}}]},{"cell_type":"code","source":"generator_test = generator(train_path, train_doc, batch_size)\nbatch_data, batch_labels = generator_test.__next__()\n    \nfor i in range(1):\n    plt.imshow(batch_data[i, 15, :, :, :])\n    plt.title(str(batch_labels[i,:]))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:08.970528Z","iopub.execute_input":"2024-05-05T19:01:08.970829Z","iopub.status.idle":"2024-05-05T19:01:13.427440Z","shell.execute_reply.started":"2024-05-05T19:01:08.970806Z","shell.execute_reply":"2024-05-05T19:01:13.426513Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Source path =  /kaggle/input/gesture-recognition-dataset/Project_data/train ; batch size = 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model \nHere you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam.","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, InputLayer\nfrom keras.layers import Conv3D, MaxPooling3D\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras import optimizers","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:13.430255Z","iopub.execute_input":"2024-05-05T19:01:13.430542Z","iopub.status.idle":"2024-05-05T19:01:13.435709Z","shell.execute_reply.started":"2024-05-05T19:01:13.430517Z","shell.execute_reply":"2024-05-05T19:01:13.434819Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Model 1\n#### 3D Convolution","metadata":{}},{"cell_type":"code","source":"#write your model here\n\nmodel = Sequential(layers=[\n    InputLayer(shape=(30, 60, 80, 3)),\n    Conv3D(3, kernel_size=(3,3,3), activation='relu', padding='same'),\n    MaxPooling3D(pool_size=(2,2,2)),\n    Flatten(),\n    Dense(5, activation='relu'),\n    Dense(5, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:13.436973Z","iopub.execute_input":"2024-05-05T19:01:13.437759Z","iopub.status.idle":"2024-05-05T19:01:14.519678Z","shell.execute_reply.started":"2024-05-05T19:01:13.437724Z","shell.execute_reply":"2024-05-05T19:01:14.518885Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train.","metadata":{}},{"cell_type":"code","source":"optimiser = optimizers.Adam(learning_rate=0.1) #write your optimizer\nmodel.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\nprint (model.summary())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-05T19:01:14.520691Z","iopub.execute_input":"2024-05-05T19:01:14.520949Z","iopub.status.idle":"2024-05-05T19:01:14.550588Z","shell.execute_reply.started":"2024-05-05T19:01:14.520927Z","shell.execute_reply":"2024-05-05T19:01:14.549793Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n\n conv3d (\u001b[38;5;33mConv3D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m3\u001b[0m)             \u001b[38;5;34m246\u001b[0m \n\n max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m3\u001b[0m)               \u001b[38;5;34m0\u001b[0m \n\n flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54000\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n\n dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                     \u001b[38;5;34m270,005\u001b[0m \n\n dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                          \u001b[38;5;34m30\u001b[0m \n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n\n conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span> \n\n max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n\n flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54000</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n\n dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">270,005</span> \n\n dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> \n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m270,281\u001b[0m (1.03 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">270,281</span> (1.03 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m270,281\u001b[0m (1.03 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">270,281</span> (1.03 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.","metadata":{}},{"cell_type":"code","source":"train_generator = generator(train_path, train_doc, batch_size)\nval_generator = generator(val_path, val_doc, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:14.551815Z","iopub.execute_input":"2024-05-05T19:01:14.552082Z","iopub.status.idle":"2024-05-05T19:01:14.556228Z","shell.execute_reply.started":"2024-05-05T19:01:14.552059Z","shell.execute_reply":"2024-05-05T19:01:14.555264Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model_name = 'model_init_conv3d' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n    \nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001, min_delta=0.01, mode=\"min\") # write the REducelronplateau code here\ncallbacks_list = [checkpoint, LR]","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:14.557399Z","iopub.execute_input":"2024-05-05T19:01:14.559050Z","iopub.status.idle":"2024-05-05T19:01:14.567851Z","shell.execute_reply.started":"2024-05-05T19:01:14.559014Z","shell.execute_reply":"2024-05-05T19:01:14.567129Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make.","metadata":{}},{"cell_type":"code","source":"if (num_train_sequences%batch_size) == 0:\n    steps_per_epoch = int(num_train_sequences/batch_size)\nelse:\n    steps_per_epoch = (num_train_sequences//batch_size) + 1\n\nif (num_val_sequences%batch_size) == 0:\n    validation_steps = int(num_val_sequences/batch_size)\nelse:\n    validation_steps = (num_val_sequences//batch_size) + 1\n    \nprint(f'steps_per_epoch: {steps_per_epoch}')\nprint(f'validation_steps: {validation_steps}')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:14.568851Z","iopub.execute_input":"2024-05-05T19:01:14.569177Z","iopub.status.idle":"2024-05-05T19:01:14.580949Z","shell.execute_reply.started":"2024-05-05T19:01:14.569146Z","shell.execute_reply":"2024-05-05T19:01:14.579996Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"steps_per_epoch: 67\nvalidation_steps: 10\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch.","metadata":{}},{"cell_type":"code","source":"num_epochs = 50\nprint ('# epochs =', num_epochs)\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nhistory = model.fit(x=train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n                    callbacks=callbacks_list, validation_data=val_generator, \n                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:01:14.582196Z","iopub.execute_input":"2024-05-05T19:01:14.582960Z","iopub.status.idle":"2024-05-05T19:15:33.398187Z","shell.execute_reply.started":"2024-05-05T19:01:14.582929Z","shell.execute_reply":"2024-05-05T19:15:33.396610Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"# epochs = 50\nNum GPUs Available:  2\nSource path =  /kaggle/input/gesture-recognition-dataset/Project_data/train ; batch size = 10\nEpoch 1/50\n\u001b[1m 1/67\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:27\u001b[0m 5s/step - categorical_accuracy: 0.3000 - loss: 1.5892","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1714935687.245336     120 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1714935687.260962     120 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.1700 - loss: 81.8733Source path =  /kaggle/input/gesture-recognition-dataset/Project_data/val ; batch size = 10\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1714935941.896609     120 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: saving model to model_init_conv3d_2024-05-0519_01_05.270519/model-00001-23.18645-0.15988-1.60680-0.23000.keras\n\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 4s/step - categorical_accuracy: 0.1699 - loss: 81.0102 - val_categorical_accuracy: 0.2300 - val_loss: 1.6068 - learning_rate: 0.1000\nEpoch 2/50\n\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - categorical_accuracy: 0.2332 - loss: 1.6152\nEpoch 2: saving model to model_init_conv3d_2024-05-0519_01_05.270519/model-00002-1.62147-0.20965-nan-0.18889.keras\n\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - categorical_accuracy: 0.2329 - loss: 1.6153 - val_categorical_accuracy: 0.1889 - val_loss: nan - learning_rate: 0.1000\nEpoch 3/50\n\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - categorical_accuracy: 0.1940 - loss: 1.6287\nEpoch 3: saving model to model_init_conv3d_2024-05-0519_01_05.270519/model-00003-1.62125-0.20664-nan-0.16667.keras\n\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - categorical_accuracy: 0.1942 - loss: 1.6286 - val_categorical_accuracy: 0.1667 - val_loss: nan - learning_rate: 0.1000\nEpoch 4/50\n\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - categorical_accuracy: 0.1671 - loss: 1.6324\nEpoch 4: saving model to model_init_conv3d_2024-05-0519_01_05.270519/model-00004-1.63815-0.15837-nan-0.23333.keras\n\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - categorical_accuracy: 0.1670 - loss: 1.6325 - val_categorical_accuracy: 0.2333 - val_loss: nan - learning_rate: 0.1000\nEpoch 5/50\n\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - categorical_accuracy: 0.1872 - loss: 1.6271\nEpoch 5: saving model to model_init_conv3d_2024-05-0519_01_05.270519/model-00005-1.61770-0.19155-nan-0.25556.keras\n\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - categorical_accuracy: 0.1873 - loss: 1.6270 - val_categorical_accuracy: 0.2556 - val_loss: nan - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m41/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - categorical_accuracy: 0.2481 - loss: 1.6078","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# epochs =\u001b[39m\u001b[38;5;124m'\u001b[39m, num_epochs)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum GPUs Available: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:329\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    328\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 329\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    331\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"acc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(num_epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:15:33.398961Z","iopub.status.idle":"2024-05-05T19:15:33.399393Z","shell.execute_reply.started":"2024-05-05T19:15:33.399168Z","shell.execute_reply":"2024-05-05T19:15:33.399185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 2\n#### 2D Convolution + RNN","metadata":{}},{"cell_type":"code","source":"#write your model here\n\nmodel = Sequential(layers=[\n    InputLayer(shape=(30, 60, 80, 3)),\n    TimeDistributed( Conv2D(3, kernel_size=(3,3), activation='relu', padding='same' )),\n    TimeDistributed( MaxPooling2D(pool_size=(2,2)) ),\n    TimeDistributed(Flatten()),\n    GRU(5, activation='relu'),\n    Dense(5, activation='relu'),\n    Dense(5, activation='softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train.","metadata":{}},{"cell_type":"code","source":"optimiser = 'adam' #write your optimizer\nmodel.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\nprint (model.summary())","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.","metadata":{}},{"cell_type":"code","source":"train_generator = generator(train_path, train_doc, batch_size)\nval_generator = generator(val_path, val_doc, batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'model_init_conv2d_rnn' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n    \nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001) # write the REducelronplateau code here\ncallbacks_list = [checkpoint, LR]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make.","metadata":{}},{"cell_type":"code","source":"if (num_train_sequences%batch_size) == 0:\n    steps_per_epoch = int(num_train_sequences/batch_size)\nelse:\n    steps_per_epoch = (num_train_sequences//batch_size) + 1\n\nif (num_val_sequences%batch_size) == 0:\n    validation_steps = int(num_val_sequences/batch_size)\nelse:\n    validation_steps = (num_val_sequences//batch_size) + 1\n    \nprint(f'steps_per_epoch: {steps_per_epoch}')\nprint(f'validation_steps: {validation_steps}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch.","metadata":{}},{"cell_type":"code","source":"num_epochs = 2\nprint ('# epochs =', num_epochs)\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nhistory = model.fit(x=train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n                    callbacks=callbacks_list, validation_data=val_generator, \n                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(num_epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}